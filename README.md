# ğŸ§  KT Assistant: AI-Powered Knowledge Transfer Engine

**KT Assistant** is an intelligent orchestration engine designed to capture deep technical knowledge and transform it into professional, publication-ready documentation. It doesn't just record what you sayâ€”it acts as a **Senior Technical Architect**, actively interviewing you to uncover architectural nuances, operational risks, and hidden system complexities.

---

## ğŸ“½ï¸ System Workflow

```mermaid
graph TD
    User([User]) -->|Land on Page| Landing[Landing Page]
    Landing -->|Start Session| Init[Initialize Session & UUID]
    Init -->|Interrogate| Chat[Chat Interface]
    Chat -->|User Input| Analyzer{Multi-Topic Analyzer}
    Analyzer -->|Fact Extraction| Knowledge[(Session Knowledge Base)]
    Analyzer -->|Update Coverage| Progress[Real-time Coverage Scoring]
    Progress -- Confidence < Threshold --> Chat
    Progress -- Confidence >= Threshold --> Index[Index to Vector DB - Qdrant]
    Index -->|Enable Search| RAG[Ask Questions to your Knowledge Base]
    Knowledge -->|On Completion| Final[Final KT Report Generation]
    Final -->|Styling| PDF[Strictly B&W Technical PDF]
```

---

## âœ¨ Core Pillars

### ğŸ™ï¸ 1. Active Interrogation Engine
Uses a **Multi-Model Pipeline** (via Gemini 1.5) to drive structured conversations:
- **Fact Extraction**: Automatically parses unstructured chat into high-fidelity JSON schemas.
- **Missing Gap Detection**: Identifies vague explanations and dynamically pivots the conversation to target specific "Missing Sections."
- **Inquisitive Reasoning**: Asks probing questions about error handling, deployment steps, and edge cases.

### ğŸ“Š 2. Real-Time Coverage Scoring
- **Dynamic Tracking**: Monitors progress across three core pillars:
    - **System Overview**: High-level purpose and core definitions.
    - **Architecture & Data Flow**: Inputs, outputs, and internal mechanics.
    - **Operations & Reliability**: Failure cases, monitoring, and recovery steps.
- **threshold-Based Completion**: Only allows final summary generation once a verified confidence score (e.g., 85%) is met for all topics.

### ğŸ” 3. Semantic Search (RAG)
- **Live Indexing**: As soon as a topic is "Complete," it is indexed into **Qdrant** with high-dimensional embeddings (3072-dim).
- **Knowledge Retrieval**: Users can search their own interview history using natural language to retrieve specific details instantly.

### ğŸ“„ 4. Knowledge Upload
- **Bootstrapping**: Don't start from scratch. Upload existing PDF or TXT documentation.
- **Auto-Parsing**: The assistant extracts text and automatically maps it to relevant topics, instantly boosting coverage scores.

### ğŸ“„ 5. Professional Artifact Generation
- **Strictly B&W PDF**: Generates high-contrast, professional technical documents with:
    - **Markdown Tables** for Data Flow and Input/Output mappings.
    - **Operational Checklists** for SRE/Ops teams.
    - **No-Color Design**: Optimized for printing and professional distribution.

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology |
| :--- | :--- |
| **Frontend** | Streamlit (Custom Premium CSS & Glassmorphism) |
| **Orchestration** | LiteLLM (Gemini Models) |
| **Database** | Supabase (PostgreSQL) |
| **Vector DB** | Qdrant |
| **PDF Rendering** | Markdown-PDF |
| **Models** | Gemini Models |

---

## ğŸš€ Getting Started

### 1. Prerequisites
- Python 3.10+
- Poetry
- Qdrant Cluster (Cloud or Local)
- Supabase Account
- Google AI Studio API Key (Gemini)

### 2. Installation
Install the project dependencies using Poetry:
```bash
# 1. Clone the repository
git clone https://github.com/Nikhil-Maheshwari-10/KT-assistant.git
cd KT-assistant

# 2. Install dependencies (creates a virtual environment automatically)
poetry install
```

### 3. Environment Setup
Copy the example environment file and fill in your details:
```bash
cp .env.example .env
```

Your `.env` file should be configured with the following parameters:

| Variable | Description |
| :--- | :--- |
| **SUPABASE_URL** | Your Supabase project URL |
| **SUPABASE_KEY** | Your Supabase service/anon key |
| **QDRANT_URL** | Endpoint for your Qdrant vector database |
| **QDRANT_API_KEY** | API Key for Qdrant authentication |
| **PRIMARY_MODEL_NAME** | Model for core reasoning |
| **SECONDARY_MODEL_NAME** | Model for rapid chat |
| **GEMINI_API_KEY** | Your Google AI Studio API Key |
| **EMBEDDING_MODEL** | Embedding model |
| **KT_CONFIDENCE_THRESHOLD**| Completeness % required before summary/search unlocks |
| **EMBEDDING_DIM** | Dimensions of the embedding vectors |

### 4. Running the Application
You can run the application directly through Poetry:
```bash
poetry run python main.py
```


## ğŸ“ Project Architecture

```text
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/                   # Config, Logger, and Base Settings
â”‚   â”œâ”€â”€ models/                 # Pydantic Schemas (Session, Topic, Message)
â”‚   â”œâ”€â”€ services/               
â”‚   â”‚   â”œâ”€â”€ ai_engine.py        # Interrogation logic & Summary generation
â”‚   â”‚   â”œâ”€â”€ db_service.py       # Supabase CRUD operations
â”‚   â”‚   â”œâ”€â”€ vector_service.py   # Qdrant RAG logic & Expiry cleanup
â”‚   â”‚   â””â”€â”€ doc_processor.py    # PDF/TXT extraction for uploads
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ streamlit.py            # Streamlit UI & Glassmorphism styling
â”œâ”€â”€ main.py                     # Entry point (Subprocess Orchestrator)
â””â”€â”€ requirements.txt
```

---

## ğŸ›¡ï¸ Privacy & Maintenance
- **Data TTL**: Sessions have a **6-hour Time-To-Live (TTL)**. The system automatically purges expired records and orphaned vector embeddings.
- **Session Isolation**: Each KT session carries a unique UUID; knowledge is never leaked between sessions.
- **Local Control**: All PDF generation and text processing happens in-memory or in ephemeral storage.

---
*Developed with â¤ï¸ for Technical Documentation Excellence.*
